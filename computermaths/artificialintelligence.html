<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="MathsResource.Github.io">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>MathsResource.Github.io</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          
          <h1 id="project_title">MathsResource.Github.io</h1>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:11px 15px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:11px 15px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg .tg-b44r{background-color:#cbcefb;vertical-align:top}
.tg .tg-yw4l{vertical-align:top}
.tg .tg-76so{font-size:15px;background-color:#cbcefb;vertical-align:top}
</style>

<!---------------------------------------------------------------------------->
<a href="http://MathsResource.github.io"> Main</a> | 
<a href="http://MathsResource.github.io/General"> General Maths</a> | 
<a href="http://MathsResource.github.io/Finance"> Financial Maths</a> | 
<a href="http://MathsResource.github.io/statistics"> Statistics</a> | 
<a href="http://MathsResource.github.io/Calculus"> Calculus</a> | 
<a href="http://MathsResource.github.io/DiscreteMaths"> Discrete Maths</a> | 
<a href="http://MathsResource.github.io/probability"> Probability</a>
<!---------------------------------------------------------------------------->
<ul>
	<li><a href="http://www.cse.msu.edu/~cse802/notes/ArtificialNeuralNetworks.pdf">Artificial Neural Networks – A Tutorial</a></li>
	<li><a href="http://arxiv.org/ftp/cs/papers/0308/0308031.pdf" target="_blank">Artificial Neural Networks for Beginners</a></li>
</ul>
<em><strong>Artificial Neural Networks and Artificial Intelligence</strong></em>

An Artificial Neural Network is a type of artificial intelligence that attempts to imitate the way a human brain works. Rather than using a digital model, in which all computations manipulate zeros and ones, a neural network works by creating connections between processing elements, the computer equivalent of neurons. The organization and weights of the connections determine the output.
Neural networks are particularly effective for predicting events when the networks have a large database of prior examples to draw on. Strictly speaking, a neural network implies a non-digital computer, but neural networks can be simulated on digital computers.

The field of neural networks was pioneered by Bernard Widrow of Stanford University in the 1950s. Neural networks are currently used prominently in voice recognition systems, image recognition systems, industrial robotics, medical imaging, data mining and aerospace applications.

<em><strong>Self-Organizing Map</strong></em>

A self-organizing map (SOM) is a type of artificial neural network (ANN) that is trained using unsupervised learning to produce a low-dimensional (typically two-dimensional), discretized representation of the input space of the training samples, called a <em><strong>map</strong></em>.

<em><strong>Boltzmann Machines</strong></em>

A Boltzmann machine is a type of stochastic recurrent neural network invented by Geoffrey Hinton and Terry Sejnowski. Boltzmann machines can be seen as the stochastic, generative counterpart of Hopfield nets. They were one of the first examples of a neural network capable of learning internal representations, and are able to represent and (given sufficient time) solve difficult combinatoric problems. However, due to a number of issues discussed below, Boltzmann machines with unconstrained connectivity have not proven useful for practical problems in machine learning or inference. They are still theoretically intriguing, however, due to the locality and Hebbian nature of their training algorithm, as well as their parallelism and the resemblance of their dynamics to simple physical processes. If the connectivity is constrained, the learning can be made efficient enough to be useful for practical problems.
<!--------------------------------------------------------------------------------------->

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">

    </div>

    

  </body>
</html>
