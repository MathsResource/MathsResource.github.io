<header class="entry-header"><span style="text-decoration:underline;"><strong>MA4413 Statistics For Computing</strong></span></header>
<div class="entry-content">

 

<details open=""> <summary>Overview of Course</summary> </details> 
<h3><span style="text-decoration:underline;"><strong>Part A : Introduction to Probability &Descriptive Statistics</strong></span></h3>
<strong>Revision Notes</strong>
<ul>
	<li><a title="Descriptive Statistics" href="https://dl.dropboxusercontent.com/u/6044937/Stats%20Lecture%20Notes/Part%20A%20-%20Descriptive%20Statistics.pdf" target="_blank">Descriptive Statistics</a></li>
	<li>Discrete Random Variable – <a title="Discrete RV example" href="https://dl.dropboxusercontent.com/u/6044937/Stats%20Lecture%20Notes/Part%20A%20-%20Discrete%20RV%20example.pdf" target="_blank">Example</a></li>
	<li></li>
</ul>
Lecture 1B Videos – Descriptive Statistics
<ul>
	<li>Sample Mean</li>
	<li><a title="Median of a data set" href="https://www.youtube.com/watch?v=d3todQxLegU" target="_blank">Computing the Median of a Data Set.</a></li>
	<li><a title="Introduction to Dispersion" href="http://youtu.be/qLSUh-tex20" target="_blank">Introduction to Dispersion</a></li>
	<li><a title="Boxplots" href="http://youtu.be/lkXcWoBcwjo" target="_blank">Box plots</a></li>
</ul>
<h3>Part 1A – Discrete Random Variables</h3>
<ul>
	<li><a title="Discrete RVs" href="https://www.youtube.com/watch?v=Rpr2WOE315g" target="_blank">Discrete Random Variables</a> [5:15] – Expected Value and Variance</li>
	<li><a title="Discrete RVs" href="https://www.youtube.com/watch?v=9OztH8vHFkw" target="_blank">Discrete Random Variables</a> (Part 2) [6:00]  –  Difference of Two Variables</li>
</ul>
<h3></h3>
<strong>Revision Notes </strong>

The Standardization Formula for the Normal Distribution – <a title="Norm Stand Formula" href="https://dl.dropboxusercontent.com/u/6044937/Stats%20Lecture%20Notes/Part%20B%20-%20The%20Standardization%20Formula.pdf" target="_blank">HERE</a>
<h3>Part C :</h3>
<h3>Section 4 :  Hypothesis Testing</h3>
 

 

 

<details open=""> <summary>Overview of Hypothesis Testing</summary>1) Formulating the null and alternative hypothesis.

2) Computing the Test Statistic

<strong>Part D2 Binary Classification Metrics & Inference Procedures with R</strong>

<strong>Binary Classification</strong>
<ul>
	<li>True Positives/False Positives/False Negatives</li>
	<li>Accuracy and Misclassification (<a title="Binary Class 1" href="https://dl.dropboxusercontent.com/u/6044937/Stats%20Lecture%20Notes/Part%20G%20-%20Binary%20Classification.pdf" target="_blank">HERE</a>)</li>
	<li>Class Imbalance (<a title="Class Imbalance" href="https://dl.dropboxusercontent.com/u/6044937/Stats%20Lecture%20Notes/Part%20G%20-%20Class%20Imbalance.pdf" target="_blank">HERE</a>)</li>
	<li>Precision, Recall and the F-measure</li>
</ul>
</details> 

 

 
<h3>Part E :  Information theory and Data Compression</h3>
 

 

 

<details open=""> <summary>Overview of Section</summary>
<ol>
	<li>Information and Entropy</li>
	<li>Marginal and Conditional Entropy</li>
	<li>Self -Information and Mutual Information</li>
	<li>Huffman Coding</li>
	<li>Shannon-Fano Coding</li>
</ol>
</details> 

 

 

<strong>Revision Notes</strong>
<ul>
	<li>What is Information (in relation to Probability)? – <a title="Part F - Information" href="https://dl.dropboxusercontent.com/u/6044937/Stats%20Lecture%20Notes/Part%20F%20-%20What%20is%20Information.pdf" target="_blank">here</a></li>
	<li>Rate of Information – <a title="Rate of Information" href="https://dl.dropboxusercontent.com/u/6044937/Stats%20Lecture%20Notes/Rate%20of%20Information.pdf" target="_blank">here</a></li>
	<li>Mutual and Conditional Entropy Worked Example – <a title="Worked Example" href="https://dl.dropboxusercontent.com/u/6044937/Stats%20Lecture%20Notes/Part%20F_Tutorial_Solutions.pdf" target="_blank">Here</a></li>
	<li>Binary Communication Channels (Matrices) – <a title="Binary Channels" href="https://dl.dropboxusercontent.com/u/6044937/Stats%20Lecture%20Notes/Binary%20Channels.pdf" target="_blank">Here</a></li>
	<li>Code Length and Code Efficiency – <a title="Code Length and Code Efficiency" href="https://dl.dropboxusercontent.com/u/6044937/Stats%20Lecture%20Notes/Code%20Length%20and%20Code%20Efficiency.pdf" target="_blank">Here</a></li>
	<li>Huffman Coding – <a title="Huffman Coding" href="https://dl.dropboxusercontent.com/u/6044937/Stats%20Lecture%20Notes/Huffman%20Coding.pdf" target="_blank">Here</a></li>
	<li>Entropy Coding (Shannon and Huffman) – Solution 1 – <a title="Entropy Coding" href="https://dl.dropboxusercontent.com/u/6044937/Stats%20Lecture%20Notes/Entropy%20Coding%20Example.pdf" target="_blank">Here</a></li>
	<li>Entropy Coding (Shannon and Huffman) – Solution 2 – <a title="Entropy Coding 2" href="https://dl.dropboxusercontent.com/u/6044937/Stats%20Lecture%20Notes/Entropy%20Coding%20Example%202.pdf" target="_blank">Here</a></li>
	<li>Entropy Coding (Shannon Fano ) – solution 3 – <a title="Shannon-Fano" href="https://dl.dropboxusercontent.com/u/6044937/Stats%20Lecture%20Notes/entropy%20coding%20example%203.pdf" target="_blank">Here</a></li>
</ul>
<strong>Lecture Videos</strong>
<ul>
	<li><a title="Entropy 1" href="https://www.youtube.com/watch?v=OsP8DE0ut8A" target="_blank">Entropy (Part 1)</a> Marginal Entropy [7:47]</li>
	<li>Entropy (Part 2)</li>
	<li><a title="Entropy 3" href="https://www.youtube.com/watch?v=GBPnCaR_z6M" target="_blank">Entropy (Part 3)</a>  Conditional entropy and Mutual Information [4:53]</li>
</ul>
</div>
